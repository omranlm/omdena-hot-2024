{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GNJfo6unYms0"
   },
   "source": [
    "### **Training** ###\n",
    "This notebook trains the YOLOv8 segmentation model to detect a new rooftop class. We considered the available YOLO configurationsâ€”nano, small, medium, large, and xl. While the larger sizes generally yield better results, they come with higher computational demands. To balance performance and computational expense, we chose the small YOLO model.\n",
    "\n",
    "The training datasets were derived from the RAMP dataset and prepared using the preprocessing notebook. To optimize the model results, we trained YOLO using data version 1, 2, and 3. Each data version was successively pruned (V3, V2, .. V0), meaning V3 was pruned from V2 and so on to V0 so that each version contains the prunings from all of the previous.\n",
    "\n",
    "RAMP-DATA-V0: 'Full Dataset' is 100k image-label pairs converted from RAMP's TIF-GEOJSON formats within 22 regional folders and stored in train-val-test folders with a 70-15-15 split; zipped at 15.2 GB downloaded from Source Cooperative.\n",
    "\n",
    "YOLO-DATA-V1: 'Preprocessing' was a process that resulted in 83k image-label pairs in JPG-TXT formats from 20 regions, zipped at 3.5 GB. We pruned 17k images from V0, reducing the background images from 18% to 5%. Shanghai and Paris regions were removed due to image format issues. A minimal manual review discovered a few labeling issues (n=38), ensuring the highest data quality.\n",
    "\n",
    "YOLO-DATA-V2: 'Pruning #2' resulted in 79k image-label pairs in JPG-TXT formats from 20 regions, zipped at 3.3 GB. We scored and analyzed inference results from the YOLO model trained on DATA-V1. The analysis revealed double the expected number of left-tail outliers. To improve labeling accuracy, we removed 4k outliers, assuming that most of these labels were errors.\n",
    "\n",
    "YOLO-DATA-V3: 'Zoom 19' resulted in 55k image-label pairs in JPG-TXT formats from 20 regions, zipped at 2.4 GB. We extracted the x and y scales from the TIF files and found the range to be between 0.3 and 0.52 meters per pixel, with 70% between 0.3 and 0.4. To test the effect of training near Zoom 19, which equates to 0.3 meters per pixel, we removed all image labels with scales greater than 0.4.\n",
    "\n",
    "To relieve the time constraints, we recommend training with a GPU. Google Colab's High-RAM T4 can train 100 epochs in 15 hours using a large batch size and cache enabled to minimize disk I/O. Using a 2023 laptop with a CPU, training YOLO for 100 epochs takes about 2.4 weeks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "C7HcnWcCYms1"
   },
   "outputs": [],
   "source": [
    "# !pip3 install -q ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Z-ZcgCSxm7AA"
   },
   "outputs": [],
   "source": [
    "# !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu116"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "_xawTrLwlm7F"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Using GPU for training.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "#Use GPU is avalaibepatience: 200patience: 200patience: 200patience: 200patience: 200patience: 200patience: 200patience: 200patience: 200patience: 200patience: 200patience: 200patience: 200patience: 200patience: 200patience: 200patience: 200patience: 200patience: 200patience: 200patience: 200patience: 200patience: 200\n",
    "if torch.cuda.is_available():\n",
    "  print(\"CUDA is available. Using GPU for training.\")\n",
    "  device = torch.device(\"cuda\")\n",
    "else:\n",
    "  print(\"CUDA is not available. Using CPU for training.\")\n",
    "  device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "1aik3Y-tYms2"
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "zKm1dhv5ahb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".python_history 45\n",
      "yolov8m-seg.pt 54921020\n",
      "local_training--old.ipynb 379762\n",
      "yolov8x-seg.pt 144101612\n",
      ".sudo_as_admin_successful 0\n",
      "data3_ramp_data_yolo_iou_scale.zip 2419400988\n",
      "yolov8n-seg.pt 7071756\n",
      "data1_ramp_data_yolo.zip 3508121128\n",
      ".bash_history 6472\n",
      "yolov8s-seg.pt 23914764\n",
      "yolo8s-seg_datav3.zip 49671630\n",
      ".motd_shown 0\n",
      "cuda-keyring_1.1-1_all.deb 4328\n",
      "o 1\n",
      "args_500e.yaml 504\n",
      "yolo11n.pt 5613764\n",
      ".profile 807\n",
      "yolov8l-seg.pt 92417004\n",
      ".bash_logout 220\n",
      ".rediscli_history 12\n",
      "args_500e_tuned.yaml 516\n",
      "data2_ramp_data_yolo_iou.zip 3271157430\n",
      ".bashrc 3771\n",
      "local_training.ipynb 235208\n",
      "yolov8_-seg.zip 298131335\n",
      "data.yaml 93\n"
     ]
    }
   ],
   "source": [
    "for entry in os.scandir('.'):\n",
    "    if entry.is_file():\n",
    "        print(entry.name,entry.stat().st_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Setting the starting model\n",
    "MODEL = 'yolov8m-seg.pt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "XBIHxuVYYms2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which dataset do you want to download? Enter 'v1', 'v2', or 'v3':  v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset already exists\n",
      "Models exists already...\n"
     ]
    }
   ],
   "source": [
    "data_choice = input(\"Which dataset do you want to download? Enter 'v1', 'v2', or 'v3': \")\n",
    "\n",
    "if data_choice.lower() == 'v1':\n",
    "    print(\"\\nunzipping data1_ramp_data_yolo.zip\")\n",
    "    # !unzip -q -o data3*.zip\n",
    "elif data_choice.lower() == 'v2':\n",
    "   if os.path.isdir('ramp_data_yolo_iou'):\n",
    "       print(\"\\nDataset already exists\")\n",
    "   else:\n",
    "       print(\"\\nunzipping data2_ramp_data_yolo_iou.zip\")\n",
    "       !unzip -q -o data2*.zip\n",
    "elif data_choice.lower() == 'v3':\n",
    "    print(\"\\nunzipping data3_ramp_data_yolo.zip\")\n",
    "    # !unzip -q -o data3*.zip\n",
    "else:\n",
    "    print(\"Invalid input.\")\n",
    "\n",
    "if os.path.isfile(MODEL):\n",
    "    print('Models exists already...')\n",
    "else:\n",
    "    print('zipping models...')\n",
    "    !unzip -q -o yolov8_-seg.zip\n",
    "\n",
    "# # Download and unzip the specified data version\n",
    "# if data_choice.lower() == 'v1':\n",
    "#     print(\"\\nDownloading and unzipping v1...\")\n",
    "#     !gdown --fuzzy https://drive.google.com/file/d/1iosxGOyBXNXoAdvdxIR7DTSWKRVLijqa/view?usp=sharing\n",
    "#     !unzip -q data1*.zip\n",
    "# elif data_choice.lower() == 'v2':\n",
    "#     print(\"\\nDownloading and unzipping v2...\")\n",
    "#     !gdown --fuzzy https://drive.google.com/file/d/1zXwvKLxzzOBp1bQ67nqfOgM55BI6sHho/view?usp=sharing\n",
    "#     !unzip -q data2*.zip\n",
    "# elif data_choice.lower() == 'v3':\n",
    "#     print(\"\\nDownloading and unzipping v3...\")\n",
    "#     !gdown --fuzzy https://drive.google.com/file/d/1K-jaOylXjukvCC6Uu8Ms2e7LxfL0-qWg/view?usp=sharing\n",
    "#     !unzip -q data3*.zip\n",
    "# else:\n",
    "#     print(\"Invalid input.\")\n",
    "\n",
    "# Download and unzip models if not found.\n",
    "# if not os.path.exists('yolov8s-seg.pt'):\n",
    "#     print('\\nDownloading and unzipping YOLOv8 models...')\n",
    "#     !gdown --fuzzy https://drive.google.com/file/d/189U5fTomw3-QPjPpkppiXVSKa-sVIQIl/view?usp=sharing\n",
    "#     print('Unzipping models...')\n",
    "#     !unzip -q yolov8_-seg.zip\n",
    "#     print('Models downloaded')\n",
    "# else:\n",
    "#     print('\\nModels already downloaded')\n",
    "\n",
    "# Download the training arguments\n",
    "# print('\\nDownloading training arguments...')\n",
    "# !gdown --fuzzy https://drive.google.com/file/d/13KLv4ywEVNVQHWhahIapSDDEzJWcAmT_/view?usp=sharing\n",
    "# !gdown --fuzzy https://drive.google.com/file/d/1_N8H6akiKqFwezDjqfjVuXDvuP6zJZGP/view?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "R4yCQSsdYms3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing the data file with path=/home/omran/ramp_data_yolo_iou\n"
     ]
    }
   ],
   "source": [
    "# Write the YAML file for YOLO that contains the class names and train/val paths\n",
    "YAML = 'data.yaml'\n",
    "\n",
    "# Set the path based on the version of the dataset\n",
    "if data_choice == 'v1':\n",
    "    path = f'{os.getcwd()}/ramp_data_yolo'\n",
    "elif data_choice == 'v2':\n",
    "    path = f'{os.getcwd()}/ramp_data_yolo_iou'\n",
    "elif data_choice == 'v3':\n",
    "    path = f'{os.getcwd()}/ramp_data_yolo_iou_scale'\n",
    "\n",
    "# Set the attribute for the YAML file\n",
    "attr = {\n",
    "    'path': path,\n",
    "    'train': 'train/images',\n",
    "    'val': 'val/images',\n",
    "    'names': {\n",
    "        0: 'rooftop'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Print the path\n",
    "print(f'Writing the data file with path={path}')\n",
    "\n",
    "# Write the file\n",
    "with open(YAML, 'w') as f:\n",
    "    yaml.dump(attr, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "UK9WryfghhqY"
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade google-api-python-client google-auth-httplib2 google-auth-oauthlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ny2nFtPyQmpi"
   },
   "outputs": [],
   "source": [
    "# # HIGHLY RECOMMENDED if your training is of a long duration\n",
    "# # Connect to Google Drive so that if session is terminated you can resume\n",
    "# from google.colab import drive\n",
    "\n",
    "# # Uncomment if needed\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "b-GYo9bNYms3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to start or resume training? Enter 'new' for new training or 'resume' to resume training:  resume\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming training...\n",
      "Loading model from ///home/omran/yolov8m-seg_data_v2/weights/last.pt\n",
      "New https://pypi.org/project/ultralytics/8.3.29 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.27 ðŸš€ Python-3.10.6 torch-2.5.0+cu124 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/home/omran/yolov8m-seg_data_v2/weights/last.pt, data=data.yaml, epochs=500, time=None, patience=500, batch=64, imgsz=256, save=True, save_period=-1, cache=disk, device=cuda, workers=8, project=/, name=yolov8m-seg_data_v2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=/home/omran/yolov8m-seg_data_v2/weights/last.pt, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=False, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.00854, lrf=0.01232, momentum=0.95275, weight_decay=0.00058, warmup_epochs=3.82177, warmup_momentum=0.81423, warmup_bias_lr=0.0, box=7.48109, cls=0.775, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.01269, hsv_s=0.68143, hsv_v=0.27, degrees=15.75, translate=0, scale=0, shear=0, perspective=0.0, flipud=0.5, fliplr=0.255, bgr=0.0, mosaic=0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/home/omran/yolov8m-seg_data_v2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27,240,227 parameters, 27,240,211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 537/537 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/omran/ramp_data_yolo_iou/train/labels.cache... 55617 images, 2983 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆ\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (10.2GB Disk): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55617/55617 [00:01<00:00, 34044.31it/s]\u001b[0m \n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/omran/ramp_data_yolo_iou/val/labels.cache... 11907 images, 629 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mCaching images (2.2GB Disk): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11907/11907 [00:00<00:00, 33652.29it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to /home/omran/yolov8m-seg_data_v2/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.00854' and 'momentum=0.95275' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.00058), 96 bias(decay=0.0)\n",
      "Resuming training /home/omran/yolov8m-seg_data_v2/weights/last.pt from epoch 472 to 500 total epochs\n",
      "Image sizes 256 train, 256 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/omran/yolov8m-seg_data_v2\u001b[0m\n",
      "Starting training for 500 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    472/500      5.68G     0.9001      1.244     0.7361     0.9127          2        256: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 870/870 [09:5\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      11907     189826      0.773      0.698      0.759      0.488      0.764      0.679      0.742       0.42\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    473/500      5.89G     0.9051      1.243     0.7396     0.9147          9        256: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 870/870 [11:0\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      11907     189826      0.773      0.698      0.758      0.488      0.764       0.68      0.741       0.42\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    474/500      6.08G      0.904      1.242     0.7412      0.914         11        256: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 870/870 [10:3\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      11907     189826      0.772      0.698      0.758      0.488      0.764      0.679      0.741      0.419\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    475/500      5.67G     0.9026       1.24     0.7399     0.9139         14        256: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 870/870 [09:5\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      11907     189826      0.772      0.698      0.757      0.487      0.764      0.679       0.74      0.419\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    476/500      5.82G     0.9029      1.241     0.7467      0.914          3        256: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 870/870 [10:0\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      11907     189826      0.771      0.698      0.757      0.487      0.764      0.679       0.74      0.419\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    477/500      5.78G     0.8993      1.233     0.7611     0.9118          0        256: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 870/870 [09:5\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      11907     189826      0.771      0.698      0.757      0.487      0.763      0.679      0.739      0.418\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    478/500      6.07G     0.8987      1.233     0.7343     0.9113         28        256: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 870/870 [10:1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      11907     189826      0.772      0.697      0.756      0.486      0.764      0.678      0.739      0.418\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    479/500      5.86G     0.8988      1.231     0.7311     0.9106         11        256: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 870/870 [10:0\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      11907     189826      0.772      0.697      0.756      0.486      0.763      0.678      0.738      0.418\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    480/500      5.87G     0.8968      1.228     0.7285     0.9108         17        256: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 870/870 [10:0\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      11907     189826      0.772      0.697      0.756      0.485      0.764      0.678      0.738      0.417\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    481/500      5.66G     0.8953      1.229     0.7286     0.9092         27        256: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 870/870 [09:2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      11907     189826      0.772      0.697      0.755      0.485      0.764      0.678      0.738      0.417\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    482/500      5.59G     0.8938      1.232     0.7259     0.9095         14        256: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 870/870 [09:2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      11907     189826      0.772      0.697      0.755      0.485      0.763      0.678      0.738      0.417\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    483/500      5.63G     0.8928      1.222     0.7233     0.9104         28        256: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 870/870 [09:2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      11907     189826      0.772      0.697      0.755      0.484      0.763      0.677      0.737      0.417\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    484/500      5.81G     0.8918      1.221     0.7237     0.9106         23        256: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 870/870 [09:2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      11907     189826      0.771      0.697      0.754      0.484      0.764      0.677      0.737      0.416\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    485/500      5.75G      0.887      1.213     0.7646     0.9073          0        256: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 870/870 [09:2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      11907     189826      0.771      0.697      0.754      0.484      0.764      0.677      0.736      0.416\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    486/500      5.83G     0.8879      1.215     0.7238      0.908          1        256: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 870/870 [09:1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      11907     189826      0.769      0.698      0.753      0.483      0.763      0.677      0.736      0.416\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    487/500      5.77G     0.8849      1.209     0.7101     0.9061         13        256: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 870/870 [09:1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      11907     189826       0.77      0.697      0.753      0.483      0.762      0.677      0.735      0.415\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    488/500      5.83G     0.8843      1.205     0.7095     0.9062         28        256: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 870/870 [09:1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      11907     189826      0.769      0.698      0.753      0.482      0.762      0.677      0.735      0.415\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    489/500      5.62G     0.8811      1.204     0.7091     0.9055          2        256: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 870/870 [09:3\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      11907     189826      0.769      0.697      0.752      0.482      0.761      0.677      0.735      0.415\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    490/500      5.79G     0.8797        1.2     0.7042     0.9042          4        256: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 870/870 [09:2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      11907     189826      0.769      0.697      0.752      0.482      0.761      0.677      0.734      0.414\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    491/500      5.75G     0.8778      1.196     0.6989     0.9043         16        256: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 870/870 [09:2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      11907     189826      0.769      0.697      0.751      0.481      0.761      0.677      0.734      0.414\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    492/500      5.89G     0.8763       1.19     0.6988     0.9037          2        256: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 870/870 [09:2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      11907     189826      0.769      0.697      0.751      0.481       0.76      0.677      0.734      0.414\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    493/500      5.55G      0.876      1.195     0.6956      0.903         18        256: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 870/870 [09:2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      11907     189826      0.769      0.696      0.751      0.481       0.76      0.677      0.733      0.413\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    494/500      5.67G     0.8734      1.188     0.6904     0.9017         12        256: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 870/870 [09:1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      11907     189826      0.769      0.696       0.75       0.48      0.761      0.676      0.733      0.413\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    495/500      6.11G     0.8721      1.187     0.6909     0.9017         32        256: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 870/870 [09:2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      11907     189826      0.769      0.696       0.75       0.48       0.76      0.677      0.733      0.413\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    496/500      5.83G     0.8703      1.185     0.6971     0.9019          3        256: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 870/870 [09:2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      11907     189826      0.769      0.696      0.749      0.479      0.761      0.676      0.732      0.413\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    497/500      5.83G      0.869      1.182      0.685     0.9018         11        256: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 870/870 [09:2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      11907     189826      0.769      0.696      0.749      0.479      0.761      0.676      0.732      0.412\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    498/500      5.79G     0.8664      1.175     0.6821     0.9005          2        256: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 870/870 [09:1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      11907     189826      0.767      0.697      0.749      0.479      0.761      0.675      0.732      0.412\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    499/500       5.8G     0.8658       1.18      0.679     0.9007         11        256: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 870/870 [09:1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      11907     189826      0.767      0.697      0.749      0.479      0.761      0.675      0.732      0.412\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    500/500      5.83G     0.8621       1.17     0.7154     0.8987          0        256: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 870/870 [09:2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      11907     189826      0.767      0.696      0.748      0.478      0.761      0.676      0.731      0.412\n",
      "\n",
      "29 epochs completed in 8.417 hours.\n",
      "Optimizer stripped from /home/omran/yolov8m-seg_data_v2/weights/last.pt, 54.9MB\n",
      "Optimizer stripped from /home/omran/yolov8m-seg_data_v2/weights/best.pt, 54.9MB\n",
      "\n",
      "Validating /home/omran/yolov8m-seg_data_v2/weights/best.pt...\n",
      "Ultralytics 8.3.27 ðŸš€ Python-3.10.6 torch-2.5.0+cu124 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27,222,963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      11907     189826      0.783      0.714      0.798      0.527      0.776      0.694      0.779      0.452\n",
      "Speed: 0.1ms preprocess, 2.2ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Results saved to \u001b[1m/home/omran/yolov8m-seg_data_v2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# For testing purposes the fraction argument can be used to train on a subset of the data\n",
    "FRACTION = 1.0\n",
    "\n",
    "# Setting the project name\n",
    "PROJECT = '/'\n",
    "\n",
    "# Load the arguments from YAML\n",
    "ARGS_FN = 'args_500e_tuned.yaml'\n",
    "with open(ARGS_FN, 'r') as f:\n",
    "    args = yaml.safe_load(f)\n",
    "\n",
    "# Generate a name for the training session\n",
    "name = f'{os.getcwd()}/{MODEL}_data_{data_choice}'\n",
    "name = name.replace('.pt', '')\n",
    "\n",
    "# Prompt the user for input\n",
    "choice = input(\"Do you want to start or resume training? Enter 'new' for new training or 'resume' to resume training: \")\n",
    "\n",
    "# Process the user input\n",
    "if choice.lower() == 'new':\n",
    "    print(\"\\nStarting new training...\\n\")\n",
    "\n",
    "    # Load the model\n",
    "    model = YOLO(MODEL)\n",
    "\n",
    "    # Modify the model's metrics to include IoU\n",
    "    model.metrics = ['metrics.box','metrics.mask', 'metrics.seg']\n",
    "\n",
    "\n",
    "    # Train the model\n",
    "    results = model.train(data=YAML, fraction=FRACTION, project=PROJECT, name=name,device=device, **args)\n",
    "\n",
    "elif choice.lower() == 'resume':\n",
    "    print(\"Resuming training...\")\n",
    "\n",
    "    # Load the model\n",
    "    modelwpath = f'{PROJECT}/{name}/weights/last.pt'\n",
    "    print(f'Loading model from {modelwpath}')\n",
    "    model = YOLO(modelwpath)\n",
    "\n",
    "    # Modify the model's metrics to include IoU\n",
    "    model.metrics = ['metrics.box','metrics.mask', 'metrics.seg']\n",
    "\n",
    "    # Resume training\n",
    "    results = model.train(resume=True)\n",
    "\n",
    "else:\n",
    "    print(\"Invalid input.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
